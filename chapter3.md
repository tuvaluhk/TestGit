# 第三章、内存**Consistency**动机与顺序**Consistency**

## 3.1 共享内存行为存在的问题

​	在下面**表3.1**中的内存指令执行后，许多程序员是希望r2得到值NEW，但在一些计算机系统里，r2的值可能会是0。为什么会有不一样的结果呢，硬件使r2的值为0是由于对store指令**S1、S2的重新排序**，因为从C1的角度看，S1、S2的执行顺序为S1、S2或S2、S1结果应该是一样的，因为它们是对不同内存地址的存储。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125144735124.png" alt="image-20210125144735124" style="zoom:80%;" />

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125145444580.png" alt="image-20210125145444580" style="zoom:80%;" />

***

> ​	**补充：内核重新排序内存访问的情况**
>
> ​	根据重新排序的内存操作是读/写分为三种情况：
>
> ​	**写-写重新排序**：内核中有**非先进先出（non-FIFO）**的写缓存，使不按进入顺序执行写入。通常会在第一条写指令未命中时发生而**①第二条写指令命中**或**②第二条写指令与更早的写入重合了**，内核会对这两条写入重新排序。这个问题对单线程的执行没有影响，但会影响我们的多线程系统。而且即使在完全遵守coherent内存的内存系统里，这种情况也会发生，因为缓存对核而言是透明的。
>
> ​	**读-读重新排序**：**动态排序核（dynamically-scheduled core）**会不按程序顺序执行指令，比如在表3.1中，C2会将L1、L2不按顺序执行，只考虑单线程即C2里的顺序，似乎是没问题的，但是跟👆介绍的C1重新排序一样，程序就会以L2、S1、S2、L1的顺序执行，r2的值为0。而当B1省略时，就更难看出区别了。
>
> ​	**读-写、写-读重新排序**：**有故障的内核**可能也会对来自同个线程对不同地址的读/写进行重新排序。读-写重排序（或写-读）可以导致许多不正确的内存行为，比如写入值如果解锁了一个被锁上的值（比如改变了分支指令的条件）使该值可被读取。比如在表3.3，将C1的S1、L1和C2的S2、L2都重新排序，得到r1、r2结果都为0 的反常结果。这种写-读重新排序在**缺少本地FIFO写缓存**的情况下也会发生，即便这个内核按照程序顺序执行所有指令。
>
> <img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125154613659.png" alt="image-20210125154613659" style="zoom:80%;" />

***

​	这是满足coherence，不违反SWMR特性的内存行为，所以，incoherence并不是这个似乎不正确结果的内因。重新考虑表3.3的执行结果，直观的结果会有3中：

* （r1，r2） = （0，NEW）以S1、L1、S2、L2顺序执行
* （r1，r2） = （NEW， 0）以S2、L2、S1、L1顺序执行
* （r1，r2） = （NEW，NEW）例如以S1、S2、L1、L2顺序执行（有别的执行顺序也是这个结果）

   例子里的结果都是不确定的，但从一开始，所有目前的多处理核处理结果都是不确定的，所有见到的结构都支持并行线程执行时有多种可能的交错执行。更多时候，确定性是由软件合适的同步机制创造出来的，因此，在定义共享内存行为时必须考虑不确定性。

## 3.2 内存consistency定义

​	上一节介绍的内存行为是很微妙的，它们给出了精确的定义**（a）程序员可以预测内存会有什么行为** **（b）系统实现者可以采取怎样的优化方法**，一个内存consistency模型是用于解决这两个问题。

​	**内存consistency模型**是对在共享内存上执行的多线程程序的允许行为的规定。对一个处理指定输入数据的多线程程序，内存一致性模型规定了**动态负载可能的返回值**和**内存的最终状态**。

​	简单而言，内存一致性模型MC给出规则，把执行划分为**遵守MC**与**不遵守MC**的执行。执行的划分反之将系统实现划分为**MC实现**与**非MC实现**，MC实现**仅**允许符合MC的执行，非MC实现**偶尔**允许不遵守MC的执行。

## 3.3 CONSISTENCY 与 COHERENCE

​	第二章介绍的CONHERENCE使用SWMR不变式规定数据的访问，使用Data-Value不变式规定数据的传递。

​	看起来coherence规定了内存行为，其实没有，因为以下原因：

* 缓存一致性的目的是使多核系统中的缓存像单核系统的一样**功能上是透明的**，但如果它是透明的，还存在什么行为呢?
* 缓存一致性通常**一次处理一个缓存块**，对多个缓存块的交互不起作用，真实的程序是跨多缓存块执行的。
* .实现内存系统是可以不用实现缓存一致性协议甚至不用缓存。

尽管coherence不是必须的，但大部分共享内存系统都使用coherent缓存实现consistency模型，甚至，认为将consistency实现从coherence实现中**分离**出来是可能且非常有价值的，所以接下来章节实现的consistency实现将coherence作为**子程序**调用即不涉及实现方法。

## 3.4 顺序CONSISTENCY(SC)基本思想

​	**sequential consistency（SC顺序一致性）**可以说是最直观的内存*consistency*模型，由*Leslie lamport*定义。单核sequential定义为**“执行的结果与按程序指定的顺序执行操作相同”**，在多核处理器里*sequentially consistent*定义为**“任何执行的结果与所有处理器（核）的操作按某种次序顺序执行相同，每个核的操作在这个次序里的顺序由它跑的程序决定”**。总操作顺序叫做**内存顺序**，在SC中，内存顺序就代表每个内核的程序顺序，其它consistency模型可能不是这样的。

​	**图3.1**描述了示例程序，中间向下的箭头是内存顺序，用（**<m**）表示，两边向下的箭头是C1、C2各自的程序顺序，用（**<p**）表示。比如op1 <m op2表示 op1 在内存执行顺序上比 op2 快，在核里的表示为：op1 <p op2 op1在这个核的程序顺序上优先于op2。在SC里，内存顺序代表每个核的程序顺序，就是 op1 <p op2 就代表着 op1 <m op2。所以在**图3.1**里，程序的运行结果是 r2 的值为NEW。这就显示出SC的价值，在**表3.1**的程序里，要得到同样的结果，你需要自己研发一个简单的SC。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125191823293.png" alt="image-20210125191823293" style="zoom:80%;" />

​	在**图3.2**里更进一步显示了SC的价值，**图3.2**阐述**表3.3**的四种执行方法**图3.2（a-c）**是是三种输出（r1,r2）=（0，NEW），（NEW，New）或（NEW，NEW）。然后**图3.2（c）**只描述了得到（NEW，NEW）的四种SC执行中的一种。

​	图3.2（d）显示的是对应（r1，r2）=（0，0）的一种**非-SC执行**，程序执行顺序如下：

* S1 <p L1
* S2 <p L2

内存执行顺序：

* L1 <m S2(r1 = 0)
* L2 <m S1(r2 = 0)

  这不一样的执行顺序造成一个循环，图3.2（d）额外的箭头描述了这个循环。

​	我们还注意到*consistency*和*coherence*的关键区别，*Coherence*用在**每个缓存块**，然而*consistency***适用于所有块**。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125202318796.png" alt="image-20210125202318796" style="zoom:80%;" />

## 3.5 SC的形式

​	（1）所有核把装载核存储指令按它们核内的顺序注入到内存总顺序中，不管是不是对同个地址的操作,分为四种情况：

* If L(a) <p L(b) ⇒ L(a) <m L(b) /* Load→Load */  
* If L(a) <p S(b) ⇒ L(a) <m S(b) /* Load→Store */  
* If S(a) <p S(b) ⇒ S(a) <m S(b) /* Store→Store */  
* If S(a) <p L(b) ⇒ S(a) <m L(b) /* Store→Load */  

​     （2）每个读指令从上一个同地址的写指令中取值 L(a) = Value of MAX ~<m~ {S(a) | S(a) <m L(a)}  , MAX ~<m~表示**“内存顺序中最近的”**

​	原子*read-modify-write(RMW)*指令，比如原子指令*test-and-set*，要求*test*的读指令逻辑上与*set*是连续的（其中没有插入其它对同地址的地址）。**表3.4**指定了*consistency*模型强制的程序顺序：**“X”表示这些操作必须按照程序顺序执行，比如两个LOAD必须按照顺序执行**，所以在SC里，所有操作都必须顺序执行。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125203424372.png" alt="image-20210125203424372" style="zoom:80%;" />

## 3.6 SC的简单实现

**多任务处理器**

首先，我们可以为多线程用户级别上实现SC，通过在**单个sequential核**上运行所有线程。在上下文开关切换到线程T2前，线程T1的指令在C1核上执行，在一个上下文切换内，任何待完成的内存操作必须在转换到新线程前完成，还包含一个关于是否遵守SC规则的检查。

**开关**

接下来，我们可以使用**一组核，一个开关，内存**实现SC，比如**图3.3**中描述一样，**每次每个核**按照自身的顺序执行内存操作。这种实现方式下可以采用对每个核的优化比如五级流水线与分支预测方法，开关也可以采用任何方法保证每个核都被服务。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125204405755.png" alt="image-20210125204405755" style="zoom:80%;" />

**评价**

*switch*实现提供了一个可操作的模型（1）允许SC执行（2）符合SC实现的“基本标准”，也证明了SC实现可以不适用缓存或*coherence*。

*switch*的缺点是不能扩展，而且由于顺序的瓶颈是一次用一个核核只有一个开关/内存。

## 3.7 使用缓存coherence的SC简单实现

​	*Cache coherence*帮助SC实现能够实现**无冲突读写**——当至少其中一个为写是两个地址相同的操作会冲突——且完全并行，而且概念上是很简单的。这里使用的Coherence遵守SWMR，部分内容：

* modified（**M**）状态表示一个一个核可以写核读的一级缓存块
* shared（**S**）状态表示一个单核或多核只能读的一级缓存块
* 使用GetM核GetS表示M块或S块的一致性需求

   **图3.4（a）**模型描述了使用代表**黑盒的cache-coherent内存系统**代替使用开关和内存的**图3.3**模型，每次单个内核在cache-coherent的内存系统上执行程序上的内存操作，在该核开始下个请求前，内存系统会全力完成每个请求。

​	**图3.4（b）**稍微打开黑盒，里面每个**核与自身的一级缓存相连**，如果块B有**恰当的一致性许可**（M/S读许可M写许可），内存系统就能对块B的读与写指令回应。而且，内存系统可以并行得对不同内核的请求回应，只要对应核的一级缓存都有合适的允许。**图3.5（a）**描述了四个核请求内存操作时的一级缓存状态，这四个操作不冲突且能被各自的一级缓存满足，因此可以并行完成。在**图3.5（b）**中，我们可以装载SC执行模型中分配它们的内存顺序，更进一步地说，能被各自的一级缓存满足的操作总是能并行完成的，因为**SWMR保证了它们是互不冲突**的（要先满足cache coherent 的 SWMR 缓存才能允许执行）。

**评价**

这种SC实现是：

* 充分利用缓存的延迟和带宽优势
* 随着缓存一致性协议可拓展
* 从实现缓存一致性协议中将核的实现分离出来

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125210549379.png" alt="image-20210125210549379" style="zoom:80%;" />

***

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210125211746177.png" alt="image-20210125211746177" style="zoom:80%;" />

## 3.8 使用cache coherence优化SC实现

​	采用*prefetch*(预取)、*speculative*(猜测执行)或*multithreading*（多线程）等方法可以提高性能且能忍受内存访问延迟。

***Non-Binding Prefetching***(非绑定预取)

​	对缓存块B的非绑定预取是要求一致性内存系统改变B在一或多个caches中的一致性状态，更一般的是,预取通常是使用**GetM**或**GetS**改变块B的一致性状态，它是软件、核硬件、缓存硬件要求的。非绑定预取不会改变寄存器的状态或B的数据，它仅限于改变缓存块的一致性状态即在**图3.4**的***cache-coherent memory system***里，基本上等于一个空操作。

***Speculative Cores***(猜测执行内核)

​	在按程序执行内存访问的同时，也执行**分支预测**——随后的内存指令开始执行，但是分支预测未命中时，会被***squash*压扁**（消除这些指令的影响）。被*squashed*的读/写指令看起来会像是*non-binding prefetch*，使这种猜测性的执行符合规定。分支预测后的读指令会在*L1cache*上执行，它要么未命中（导致一个非绑定GetS预取）或命中返回值到寄存器。如果读指令被压扁了，核会**抛弃**读指令带来的寄存器更新，擦除所有功能性的影响——就像没发生过。缓存不会擦除非绑定预取，因为这么做没必要且如果要重新取，预取可以提高性能。

***Dynamically Scheduled Cores***(动态排序内核)

​	动态排序内核是相比于**按照严格的程序顺序执行指令的静态排序核**而言的，一个采用动态或不按程序顺序排序的单核处理器必须在程序内执行**真数据依赖性**。然而，在多核处理器情况下，动态排序引入了新的问题：**memory consistency speculation**(内存一致性猜测)。问题：一个核要动态排序两个LOAD的执行，L2的地址比L1先算出来，很多核会先执行L2，这些核预测别的核对这重新排序不可见。违反SC。

​	方法一：在内核猜测性执行L2和还没提交L2**中间**，检查内核猜测性访问的块**是否没离开缓存**。只要缓存块还在cache里，在这个load执行后和提交前中间的这段时间内，它的值是不会变的。为了实现检查，内核跟踪L2访问的地址并**与缓存驱逐出的块一一对比**，同时与刚收到的内存一致性请求对比。若收到一个GetM显示其他内核能注意到L2不按顺序执行，这个GetM导致猜测miss，猜测性的执行被压扁。

​	方法二：当核准备提交装载时**重复执行**每个猜测性装载，提交的装载值要与猜测装载的值相同，否则猜测错误。比如，如果**重新执行的L2读的值与原本执行L2读的值不一致**，那这个读-读重新排序显然是不正确且要被压扁的。

***Non-Binding Prefetching in Dynamically Scheduled Cores***（动态排序内核中的非绑定预取）

​	动态排序内核很容易遇到**程序顺序之外的读写miss**，例如，假设程序顺序是Load A，Store B，然后Store C。内核可能会不按顺序执行non-binding prefetch，例如，按GetM C、GetS A、GetM B这样并行执行。即便这样，SC也不会受到影响，因为SC要求内核的**读写请求按程序顺序访问一级缓存**，而Coherence要求**一级缓存块以合适的状态接受读写指令**.

​	所以，SC规定的是读写在coherent内存上执行的顺序而不是coherence活动的顺序。

***Multithreading***  

​	SC可以以不同粒度实现**Multithreading** ，多线程核 逻辑上 = 多个通过开关共享同个一级缓存的虚拟核 开关决定哪个虚拟内核使用缓存。同时，每个缓存实际上可以同时服务于多个**不冲突请求**通过假装它们是按某种顺序执行。这里的挑战是要保证在**同一个内核上执行的线程T1在另一个线程T2**，在T2写的内容被其它核看到（即**提交到memory order**）前，T1是不能读T2写的值的。因此，当T1就要读T2注入到内存顺序中的写的内容时（T2写入处于M态的缓存块），T1不能从内核里共享的读写队列中读值。

## 3.9 SC的原子操作

​	为了编写多线程代码，程序员需要能够同步这些线程，实现同步需要引入**操作对的原子实现**。这个功能由能够**原子实现“read-modify-write”（RMW）**的指令提供，比如熟知的**“test-and-set”**、**"fetch-and-increment"**、**"compare-and-swap"。**这些原子指令对适当的同步很重要，也常用于实现spin-lock（自旋锁）和其它同步机制。对自旋锁（一种资源冲突同步机制），程序员可能会使用一个RMW去原子读锁的值是开锁（=0）或写入锁值（=1）。对原子性的RMW而言，**RMW的读和写操作**必须装载SC要求的总操作顺序上是**连续出现**的。

​	在微架构上实现原子指令的概念是直观的，但是粗糙的设计会导致原子指令的性能糟糕。一个实现原子指令简单且正确的方法是让内核锁定内存系统，然后执行内核自身的read、modify、write操作，尽管是正确且直观，但牺牲了性能。

​	进一步实现原子指令RMW:找一个有**处在M状态缓存块的内核**，在没有一致性信息或总线锁的条件下，只要这块**一直在等一致性请求传入**，内核可以在缓存中只读和写这一块，直到有对块的写指令.

​	更优化的RMW实现允许读写实现的间隔更大，更优化的RMW实现：一个处在**只读状态的缓存块**，当缓存控制器发出**更新缓存块的一致性状态到读-写**时，立刻**猜测性地执行RMW的R**，**RMW的W在读-写状态实现**。R-M-W的时间就变多了，在缓存块读状态执行R，在缓存块读-写状态执行W。只要内核保持**原子性的幻觉**，这样的实现就是正确的，为了检查原子性幻觉是否保持，需要检查写入的缓存块**在RMW的R与W间的间隔有无被驱逐**。

## 3.10 MIPS R10000

​	MIPS R10000为实现包含SC和cache-coherent的内存层次结构的猜测性为处理器提供了珍贵、简洁的商业例子，这里我们集中于R10000关于实现内存consistency的方面。

​	R10000是支持分支预测和乱序执行的四通道超标量精简指令集处理内核，R10000支持写回的L1指令和数据缓存，也支支持与共享L2缓存的独立接口。

​	芯片的主要系统接口总线支持最多4个处理器的cache coherence，如**图3.6**

​	R10000程序执行：R10000内核以程序顺序把（猜测性的）读写发往一个*address queue*，load读指令从同地址的上一个store写指令取值，如果没有，就从data cache中取值。读指令和写指令接着按程序顺序提交然后移除它们的*address queue*入口。提交store，L1cache要把对应块维持在M状态，提交的值必须是原子写写入的值。

​	重要的是，eviction被驱逐的缓存块——由于coherence状态改变或为其它块腾位置——如果块在*address queue*里有*load address*，eviction是把压扁load与随后的指令，之后会重新执行。在最后提交时，读的块在缓存中执行和提交是连续的，所以如果在提交时执行，一定要保证执行结果与提交值相同。而写指令实际上是提交时才写的,R10000在逻辑上按程序顺序在coherent memory system上执行load和write。

<img src="C:\Users\lshlab\AppData\Roaming\Typora\typora-user-images\image-20210126154339185.png" alt="image-20210126154339185" style="zoom:80%;" />

